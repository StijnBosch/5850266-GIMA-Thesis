{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6e0444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio as rs\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from osgeo import gdal, gdalconst\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d70f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Image\n",
    "def read_data_EMP(inras):\n",
    "    # Read data\n",
    "    img = gdal.Open(inras, gdal.GA_ReadOnly) \n",
    "    bands = [img.GetRasterBand(i).ReadAsArray() for i in range(1, img.RasterCount + 1)]\n",
    "    img = np.array(bands)\n",
    "    img = img[0:12,:,:]\n",
    "    img = np.transpose(img, [1, 2, 0])\n",
    "    img_rgbnir = img[:,:,[3,2,1,7]]\n",
    "    return img_rgbnir\n",
    "def MyNormalize(img_i,sigma):\n",
    "        nr,nc,nb = img_i.shape\n",
    "        img_n = np.zeros(shape=(nr,nc,nb))\n",
    "        for i in range(0,nb):\n",
    "            one_band = img_i[:,:,i]\n",
    "            mi = np.min(one_band)\n",
    "            ma = np.max(one_band)\n",
    "            one_band = (one_band-mi)/(ma-mi+np.finfo(float).eps)\n",
    "            img_n[:,:,i] = sigma*one_band\n",
    "        return img_n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1c08492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Imagery\n",
    "asisub = 'Input/Imagery/Subset_SingleDateImage_Amsterdam.tif'\n",
    "amisub = 'Input/Imagery/Subset_MedianImage_Amsterdam.tif'\n",
    "msisub = 'Input/Imagery/Subset_SingleDateImage_Milano.tif'\n",
    "mmisub = 'Input/Imagery/Subset_MedianImage_Milano.tif'\n",
    "bsisub = 'Input/Imagery/Subset_SingleDateImage_Budapest.tif'\n",
    "bmisub = 'Input/Imagery/Subset_MedianImage_Budapest.tif'\n",
    "#Import Feature extraction\n",
    "EMPas = np.load('D:/Thesis/Notebooks/Output/Sub/EMP/empasi.npy')\n",
    "NDWIas = loadtxt('D:/Thesis/Notebooks/Output/Sub/NDWI/ndwiasi.csv', delimiter=',')\n",
    "NDVIas = loadtxt('D:/Thesis/Notebooks/Output/Sub/NDVI/ndviasi.csv', delimiter=',')\n",
    "EMPam = np.load('D:/Thesis/Notebooks/Output/Sub/EMP/empami.npy')\n",
    "NDWIam = loadtxt('D:/Thesis/Notebooks/Output/Sub/NDWI/ndwiami.csv', delimiter=',')\n",
    "NDVIam = loadtxt('D:/Thesis/Notebooks/Output/Sub/NDVI/ndviami.csv', delimiter=',')\n",
    "EMPms = np.load('D:/Thesis/Notebooks/Output/Sub/EMP/empmsi.npy')\n",
    "NDWIms = loadtxt('D:/Thesis/Notebooks/Output/Sub/NDWI/ndwimsi.csv', delimiter=',')\n",
    "NDVIms = loadtxt('D:/Thesis/Notebooks/Output/Sub/NDVI/ndvimsi.csv', delimiter=',')\n",
    "EMPmm = np.load('D:/Thesis/Notebooks/Output/Sub/EMP/empmmi.npy')\n",
    "NDWImm = loadtxt('D:/Thesis/Notebooks/Output/Sub/NDWI/ndwimmi.csv', delimiter=',')\n",
    "NDVImm = loadtxt('D:/Thesis/Notebooks/Output/Sub/NDVI/ndvimmi.csv', delimiter=',')\n",
    "EMPbs = np.load('D:/Thesis/Notebooks/Output/Sub/EMP/empbsi.npy')\n",
    "NDWIbs = loadtxt('D:/Thesis/Notebooks/Output/Sub/NDWI/ndwibsi.csv', delimiter=',')\n",
    "NDVIbs = loadtxt('D:/Thesis/Notebooks/Output/Sub/NDVI/ndvibsi.csv', delimiter=',')\n",
    "EMPbm = np.load('D:/Thesis/Notebooks/Output/Sub/EMP/empbmi.npy')\n",
    "NDWIbm = loadtxt('D:/Thesis/Notebooks/Output/Sub/NDWI/ndwibmi.csv', delimiter=',')\n",
    "NDVIbm = loadtxt('D:/Thesis/Notebooks/Output/Sub/NDVI/ndvibmi.csv', delimiter=',')\n",
    "#Import Twitter\n",
    "Twita = rs.open('Input/Twitter/Subset_TwitterRaster_Amsterdam.tif','r').read()\n",
    "Twita = np.transpose(Twita, [1, 2, 0])\n",
    "Twita = Twita[:,:,0]\n",
    "Twitm = rs.open('Input/Twitter/Subset_TwitterRaster_Milano.tif','r').read()\n",
    "Twitm = np.transpose(Twitm, [1, 2, 0])\n",
    "Twitm = Twitm[:,:,0]\n",
    "Twitb = rs.open('Input/Twitter/Subset_TwitterRaster_Budapest.tif','r').read()\n",
    "Twitb = np.transpose(Twitb, [1, 2, 0])\n",
    "Twitb = Twitb[:,:,0]\n",
    "#Import Validation datasets\n",
    "Vala = rs.open('Input/Validation/Validation_30m_Amsterdam_sub.tif','r').read()\n",
    "Vala = np.transpose(Vala, [1, 2, 0])\n",
    "Val30ma = Vala[:,:,0]\n",
    "Val30ma = np.where(Val30ma==2, 1, 0)\n",
    "Val30ma = Val30ma.flatten()\n",
    "Val2a = rs.open('Input/Validation/Validation_GAIA_Amsterdam_sub.tif','r').read()\n",
    "Val2a = np.transpose(Val2a, [1, 2, 0])\n",
    "Val2GAIAa = Val2a[:,:,0]\n",
    "Val2GAIAa = np.where(Val2GAIAa>0, 1, 0)\n",
    "Val2GAIAa = Val2GAIAa.flatten()\n",
    "Val3a = rs.open('Input/Validation/Validation_GHS_Amsterdam_sub.tif', 'r').read()\n",
    "Val3a = np.transpose(Val3a, [1, 2, 0])\n",
    "Val3GHSa = Val3a[:,:,0]\n",
    "Val3GHS50a = np.where(Val3GHSa>50, 1, 0)\n",
    "Val3GHS50a = Val3GHS50a.flatten()\n",
    "\n",
    "Valm = rs.open('Input/Validation/Validation_30m_Milano_sub.tif','r').read()\n",
    "Valm = np.transpose(Valm, [1, 2, 0])\n",
    "Val30mm = Valm[:,:,0]\n",
    "Val30mm = np.where(Val30mm==2, 1, 0)\n",
    "Val30mm = Val30mm.flatten()\n",
    "Val2m = rs.open('Input/Validation/Validation_GAIA_Milano_sub.tif','r').read()\n",
    "Val2m = np.transpose(Val2m, [1, 2, 0])\n",
    "Val2GAIAm = Val2m[:,:,0]\n",
    "Val2GAIAm = np.where(Val2GAIAm>0, 1, 0)\n",
    "Val2GAIAm = Val2GAIAm.flatten()\n",
    "Val3m = rs.open('Input/Validation/Validation_GHS_Milano_sub.tif', 'r').read()\n",
    "Val3m = np.transpose(Val3m, [1, 2, 0])\n",
    "Val3GHSm = Val3m[:,:,0]\n",
    "Val3GHS50m = np.where(Val3GHSm>50, 1, 0)\n",
    "Val3GHS50m = Val3GHS50m.flatten()\n",
    "\n",
    "Valb = rs.open('Input/Validation/Validation_30m_Budapest_sub.tif','r').read()\n",
    "Valb = np.transpose(Valb, [1, 2, 0])\n",
    "Val30mb = Valb[:,:,0]\n",
    "Val30mb = np.where(Val30mb==2, 1, 0)\n",
    "Val30mb = Val30mb.flatten()\n",
    "Val2b = rs.open('Input/Validation/Validation_GAIA_Budapest_sub.tif','r').read()\n",
    "Val2b = np.transpose(Val2b, [1, 2, 0])\n",
    "Val2GAIAb = Val2b[:,:,0]\n",
    "Val2GAIAb = np.where(Val2GAIAb>0, 1, 0)\n",
    "Val2GAIAb = Val2GAIAb.flatten()\n",
    "Val3b = rs.open('Input/Validation/Validation_GHS_Budapest_sub.tif', 'r').read()\n",
    "Val3b = np.transpose(Val3b, [1, 2, 0])\n",
    "Val3GHSb = Val3b[:,:,0]\n",
    "Val3GHS50b = np.where(Val3GHSb>50, 1, 0)\n",
    "Val3GHS50b = Val3GHS50b.flatten()\n",
    "\n",
    "from numpy import *\n",
    "GLCM_ASI_load = loadtxt('D:/Thesis/Notebooks/Output/Sub/GLCM/ASI/GLCM_ASI_sub.csv', delimiter=',')\n",
    "img = read_data_EMP(asisub)\n",
    "nr, nc, nb = img.shape\n",
    "nf = 16\n",
    "GLCMas = GLCM_ASI_load.reshape(nr,nc,nf)\n",
    "where_are_NaNs = isnan(GLCMas)\n",
    "GLCMas[where_are_NaNs] = 0\n",
    "\n",
    "GLCM_AMI_load = loadtxt('D:/Thesis/Notebooks/Output/Sub/GLCM/AMI/GLCM_AMI_sub.csv', delimiter=',')\n",
    "img = read_data_EMP(amisub)\n",
    "nr, nc, nb = img.shape\n",
    "nf = 16\n",
    "GLCMam = GLCM_AMI_load.reshape(nr,nc,nf)\n",
    "where_are_NaNs = isnan(GLCMam)\n",
    "GLCMam[where_are_NaNs] = 0\n",
    "\n",
    "GLCM_MSI_load = loadtxt('D:/Thesis/Notebooks/Output/Sub/GLCM/MSI/GLCM_MSI_sub.csv', delimiter=',')\n",
    "img = read_data_EMP(msisub)\n",
    "nr, nc, nb = img.shape\n",
    "nf = 16\n",
    "GLCMms = GLCM_MSI_load.reshape(nr,nc,nf)\n",
    "where_are_NaNs = isnan(GLCMms)\n",
    "GLCMms[where_are_NaNs] = 0\n",
    "\n",
    "GLCM_MMI_load = loadtxt('D:/Thesis/Notebooks/Output/Sub/GLCM/MMI/GLCM_MMI_sub.csv', delimiter=',')\n",
    "img = read_data_EMP(mmisub)\n",
    "nr, nc, nb = img.shape\n",
    "nf = 16\n",
    "GLCMmm = GLCM_MMI_load.reshape(nr,nc,nf)\n",
    "where_are_NaNs = isnan(GLCMmm)\n",
    "GLCMmm[where_are_NaNs] = 0\n",
    "\n",
    "GLCM_BSI_load = loadtxt('D:/Thesis/Notebooks/Output/Sub/GLCM/BSI/GLCM_BSI_sub.csv', delimiter=',')\n",
    "img = read_data_EMP(bsisub)\n",
    "nr, nc, nb = img.shape\n",
    "nf = 16\n",
    "GLCMbs = GLCM_BSI_load.reshape(nr,nc,nf)\n",
    "where_are_NaNs = isnan(GLCMbs)\n",
    "GLCMbs[where_are_NaNs] = 0\n",
    "\n",
    "GLCM_BMI_load = loadtxt('D:/Thesis/Notebooks/Output/Sub/GLCM//BMI/GLCM_BMI_sub.csv', delimiter=',')\n",
    "img = read_data_EMP(bmisub)\n",
    "nr, nc, nb = img.shape\n",
    "nf = 16\n",
    "GLCMbm = GLCM_BMI_load.reshape(nr,nc,nf)\n",
    "where_are_NaNs = isnan(GLCMbm)\n",
    "GLCMbm[where_are_NaNs] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702faf40",
   "metadata": {},
   "source": [
    "## IF asi sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef733fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal OA parameter 80.50.6917568046995536\n",
      "Optimal P parameter 50.70.7209486381747721\n",
      "Optimal R parameter 100.30.9465143904528839\n",
      "Optimal F parameter 120.40.6689946795855839\n",
      "Optimal AUC parameter 80.50.7415860527112277\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#IF\n",
    "estimators = [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
    "threshold = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "AOscores = {}\n",
    "Pscores = {}\n",
    "Rscores ={}\n",
    "Fscores = {}\n",
    "AUCscores = {}\n",
    "\n",
    "\n",
    "for e in estimators:\n",
    "    for t in threshold:\n",
    "        x = str(e+t)\n",
    "        img = read_data_EMP(asisub)\n",
    "        stack = np.concatenate((img, EMPas, GLCMas), axis=2)\n",
    "        stacked = np.dstack((stack, NDVIas, NDWIas))\n",
    "        #Setup for IF and OCSVM\n",
    "        X = stacked\n",
    "        Ytr1 = Twita\n",
    "        nr,nc,nb = X.shape\n",
    "        ns = nr*nc\n",
    "        X = X.reshape((ns,nb))\n",
    "        Ytr = Ytr1.reshape((ns,))\n",
    "        ind = np.where(Ytr > 0)\n",
    "        Xtr = X[ind[0],:]\n",
    "        Ytr = Ytr[ind[0]]\n",
    "        standard_scaler = StandardScaler()\n",
    "        Xtr = standard_scaler.fit_transform(Xtr) \n",
    "        X = standard_scaler.transform(X)\n",
    "        model = IsolationForest(n_estimators = e)\n",
    "        model.fit(Xtr)\n",
    "        yhat = model.score_samples(X)\n",
    "        yhat1 = (yhat-min(yhat))/(max(yhat)-min(yhat))\n",
    "        class_map1 = np.reshape(yhat1,(nr,nc))\n",
    "        class_map = np.where(class_map1>t, 1, 0)\n",
    "        class_map = class_map.flatten()\n",
    "        pred = class_map\n",
    "        true1 = Val30ma\n",
    "        true2 = Val2GAIAa\n",
    "        true3 = Val3GHS50a\n",
    "        cfm1 = confusion_matrix(true1, pred)\n",
    "        TN1,FP1,FN1,TP1= cfm1.ravel()\n",
    "        cfm2 = confusion_matrix(true2, pred)\n",
    "        TN2,FP2,FN2,TP2= cfm2.ravel()\n",
    "        cfm3 = confusion_matrix(true3, pred)\n",
    "        TN3,FP3,FN3,TP3= cfm3.ravel()\n",
    "\n",
    "        AO = (((TP1+TN1)/(TP1+TN1+FP1+FN1))+\n",
    "              ((TP2+TN2)/(TP2+TN2+FP2+FN2))+\n",
    "              ((TP3+TN3)/(TP3+TN3+FP3+FN3)))/3\n",
    "        AOscores[x] = AO\n",
    "        \n",
    "        P = ((TP1/(TP1+FP1))+\n",
    "             (TP2/(TP2+FP2))+\n",
    "             (TP3/(TP3+FP3)))/3\n",
    "        Pscores[x] = P\n",
    "        \n",
    "        R = ((TP1/(TP1+FN1))+\n",
    "             (TP2/(TP2+FN2))+\n",
    "             (TP3/(TP3+FN3)))/3\n",
    "        Rscores[x] = R\n",
    "        \n",
    "        F = (((2*TP1)/(2*TP1+FP1+FN1))+\n",
    "             ((2*TP2)/(2*TP2+FP2+FN2))+\n",
    "             ((2*TP3)/(2*TP3+FP3+FN3)))/3\n",
    "        Fscores[x] = F\n",
    "        \n",
    "        auc1 = roc_auc_score(true1,pred)\n",
    "        auc2 = roc_auc_score(true2,pred)\n",
    "        auc3 = roc_auc_score(true3,pred)\n",
    "        score = ((auc1+auc2+auc3)/3)\n",
    "        AUCscores[x] = score\n",
    "        \n",
    "all_values = AOscores.values()\n",
    "max_value = max(all_values)\n",
    "max_key = max(AOscores, key=AOscores.get)\n",
    "print('Optimal OA parameter ' + str(max_key) + str(max_value))\n",
    "\n",
    "all_values1 = Pscores.values()\n",
    "max_value1 = max(all_values1)\n",
    "max_key1 = max(Pscores, key=Pscores.get)\n",
    "print('Optimal P parameter ' + str(max_key1) + str(max_value1))\n",
    "\n",
    "all_values2 = Rscores.values()\n",
    "max_value2 = max(all_values2)\n",
    "max_key2 = max(Rscores, key=Rscores.get)\n",
    "print('Optimal R parameter ' + str(max_key2) + str(max_value2))\n",
    "\n",
    "all_values3 = Fscores.values()\n",
    "max_value3 = max(all_values3)\n",
    "max_key3 = max(Fscores, key=Fscores.get)\n",
    "print('Optimal F parameter ' + str(max_key3) + str(max_value3))\n",
    "\n",
    "all_values4 = AUCscores.values()\n",
    "max_value4 = max(all_values4)\n",
    "max_key4 = max(AUCscores, key=AUCscores.get)\n",
    "print('Optimal AUC parameter ' + str(max_key4) + str(max_value4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe6a9e",
   "metadata": {},
   "source": [
    "## IF ami sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "938f9d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal OA parameter 110.60.6984810606998177\n",
      "Optimal P parameter 90.70.7177627564192837\n",
      "Optimal R parameter 100.30.966003920609563\n",
      "Optimal F parameter 70.50.6726246624743727\n",
      "Optimal AUC parameter 110.60.7493622346016253\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#IF\n",
    "estimators = [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
    "threshold = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "AOscores = {}\n",
    "Pscores = {}\n",
    "Rscores ={}\n",
    "Fscores = {}\n",
    "AUCscores = {}\n",
    "\n",
    "\n",
    "for e in estimators:\n",
    "    for t in threshold:\n",
    "        x = str(e+t)\n",
    "        img = read_data_EMP(amisub)\n",
    "        stack = np.concatenate((img, EMPam, GLCMam), axis=2)\n",
    "        stacked = np.dstack((stack, NDVIam, NDWIam))\n",
    "        #Setup for IF and OCSVM\n",
    "        X = stacked\n",
    "        Ytr1 = Twita\n",
    "        nr,nc,nb = X.shape\n",
    "        ns = nr*nc\n",
    "        X = X.reshape((ns,nb))\n",
    "        Ytr = Ytr1.reshape((ns,))\n",
    "        ind = np.where(Ytr > 0)\n",
    "        Xtr = X[ind[0],:]\n",
    "        Ytr = Ytr[ind[0]]\n",
    "        standard_scaler = StandardScaler()\n",
    "        Xtr = standard_scaler.fit_transform(Xtr) \n",
    "        X = standard_scaler.transform(X)\n",
    "        model = IsolationForest(n_estimators = e)\n",
    "        model.fit(Xtr)\n",
    "        yhat = model.score_samples(X)\n",
    "        yhat1 = (yhat-min(yhat))/(max(yhat)-min(yhat))\n",
    "        class_map1 = np.reshape(yhat1,(nr,nc))\n",
    "        class_map = np.where(class_map1>t, 1, 0)\n",
    "        class_map = class_map.flatten()\n",
    "        pred = class_map\n",
    "        true1 = Val30ma\n",
    "        true2 = Val2GAIAa\n",
    "        true3 = Val3GHS50a\n",
    "        cfm1 = confusion_matrix(true1, pred)\n",
    "        TN1,FP1,FN1,TP1= cfm1.ravel()\n",
    "        cfm2 = confusion_matrix(true2, pred)\n",
    "        TN2,FP2,FN2,TP2= cfm2.ravel()\n",
    "        cfm3 = confusion_matrix(true3, pred)\n",
    "        TN3,FP3,FN3,TP3= cfm3.ravel()\n",
    "\n",
    "        AO = (((TP1+TN1)/(TP1+TN1+FP1+FN1))+\n",
    "              ((TP2+TN2)/(TP2+TN2+FP2+FN2))+\n",
    "              ((TP3+TN3)/(TP3+TN3+FP3+FN3)))/3\n",
    "        AOscores[x] = AO\n",
    "        \n",
    "        P = ((TP1/(TP1+FP1))+\n",
    "             (TP2/(TP2+FP2))+\n",
    "             (TP3/(TP3+FP3)))/3\n",
    "        Pscores[x] = P\n",
    "        \n",
    "        R = ((TP1/(TP1+FN1))+\n",
    "             (TP2/(TP2+FN2))+\n",
    "             (TP3/(TP3+FN3)))/3\n",
    "        Rscores[x] = R\n",
    "        \n",
    "        F = (((2*TP1)/(2*TP1+FP1+FN1))+\n",
    "             ((2*TP2)/(2*TP2+FP2+FN2))+\n",
    "             ((2*TP3)/(2*TP3+FP3+FN3)))/3\n",
    "        Fscores[x] = F\n",
    "        \n",
    "        auc1 = roc_auc_score(true1,pred)\n",
    "        auc2 = roc_auc_score(true2,pred)\n",
    "        auc3 = roc_auc_score(true3,pred)\n",
    "        score = ((auc1+auc2+auc3)/3)\n",
    "        AUCscores[x] = score\n",
    "        \n",
    "all_values = AOscores.values()\n",
    "max_value = max(all_values)\n",
    "max_key = max(AOscores, key=AOscores.get)\n",
    "print('Optimal OA parameter ' + str(max_key) + str(max_value))\n",
    "\n",
    "all_values1 = Pscores.values()\n",
    "max_value1 = max(all_values1)\n",
    "max_key1 = max(Pscores, key=Pscores.get)\n",
    "print('Optimal P parameter ' + str(max_key1) + str(max_value1))\n",
    "\n",
    "all_values2 = Rscores.values()\n",
    "max_value2 = max(all_values2)\n",
    "max_key2 = max(Rscores, key=Rscores.get)\n",
    "print('Optimal R parameter ' + str(max_key2) + str(max_value2))\n",
    "\n",
    "all_values3 = Fscores.values()\n",
    "max_value3 = max(all_values3)\n",
    "max_key3 = max(Fscores, key=Fscores.get)\n",
    "print('Optimal F parameter ' + str(max_key3) + str(max_value3))\n",
    "\n",
    "all_values4 = AUCscores.values()\n",
    "max_value4 = max(all_values4)\n",
    "max_key4 = max(AUCscores, key=AUCscores.get)\n",
    "print('Optimal AUC parameter ' + str(max_key4) + str(max_value4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e4310",
   "metadata": {},
   "source": [
    "## IF msi sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4ab9f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal OA parameter 60.40.7089428479493082\n",
      "Optimal P parameter 60.70.7635349359874785\n",
      "Optimal R parameter 50.30.9835913827517272\n",
      "Optimal F parameter 50.30.7716623401023982\n",
      "Optimal AUC parameter 60.70.7443357658894989\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#IF\n",
    "estimators = [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
    "threshold = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "AOscores = {}\n",
    "Pscores = {}\n",
    "Rscores ={}\n",
    "Fscores = {}\n",
    "AUCscores = {}\n",
    "\n",
    "\n",
    "for e in estimators:\n",
    "    for t in threshold:\n",
    "        x = str(e+t)\n",
    "        img = read_data_EMP(msisub)\n",
    "        stack = np.concatenate((img, EMPms, GLCMms), axis=2)\n",
    "        stacked = np.dstack((stack, NDVIms, NDWIms))\n",
    "        #Setup for IF and OCSVM\n",
    "        X = stacked\n",
    "        Ytr1 = Twitm\n",
    "        nr,nc,nb = X.shape\n",
    "        ns = nr*nc\n",
    "        X = X.reshape((ns,nb))\n",
    "        Ytr = Ytr1.reshape((ns,))\n",
    "        ind = np.where(Ytr > 0)\n",
    "        Xtr = X[ind[0],:]\n",
    "        Ytr = Ytr[ind[0]]\n",
    "        standard_scaler = StandardScaler()\n",
    "        Xtr = standard_scaler.fit_transform(Xtr) \n",
    "        X = standard_scaler.transform(X)\n",
    "        model = IsolationForest(n_estimators = e)\n",
    "        model.fit(Xtr)\n",
    "        yhat = model.score_samples(X)\n",
    "        yhat1 = (yhat-min(yhat))/(max(yhat)-min(yhat))\n",
    "        class_map1 = np.reshape(yhat1,(nr,nc))\n",
    "        class_map = np.where(class_map1>t, 1, 0)\n",
    "        class_map = class_map.flatten()\n",
    "        pred = class_map\n",
    "        true1 = Val30mm\n",
    "        true2 = Val2GAIAm\n",
    "        true3 = Val3GHS50m\n",
    "        cfm1 = confusion_matrix(true1, pred)\n",
    "        TN1,FP1,FN1,TP1= cfm1.ravel()\n",
    "        cfm2 = confusion_matrix(true2, pred)\n",
    "        TN2,FP2,FN2,TP2= cfm2.ravel()\n",
    "        cfm3 = confusion_matrix(true3, pred)\n",
    "        TN3,FP3,FN3,TP3= cfm3.ravel()\n",
    "\n",
    "        AO = (((TP1+TN1)/(TP1+TN1+FP1+FN1))+\n",
    "              ((TP2+TN2)/(TP2+TN2+FP2+FN2))+\n",
    "              ((TP3+TN3)/(TP3+TN3+FP3+FN3)))/3\n",
    "        AOscores[x] = AO\n",
    "        \n",
    "        P = ((TP1/(TP1+FP1))+\n",
    "             (TP2/(TP2+FP2))+\n",
    "             (TP3/(TP3+FP3)))/3\n",
    "        Pscores[x] = P\n",
    "        \n",
    "        R = ((TP1/(TP1+FN1))+\n",
    "             (TP2/(TP2+FN2))+\n",
    "             (TP3/(TP3+FN3)))/3\n",
    "        Rscores[x] = R\n",
    "        \n",
    "        F = (((2*TP1)/(2*TP1+FP1+FN1))+\n",
    "             ((2*TP2)/(2*TP2+FP2+FN2))+\n",
    "             ((2*TP3)/(2*TP3+FP3+FN3)))/3\n",
    "        Fscores[x] = F\n",
    "        \n",
    "        auc1 = roc_auc_score(true1,pred)\n",
    "        auc2 = roc_auc_score(true2,pred)\n",
    "        auc3 = roc_auc_score(true3,pred)\n",
    "        score = ((auc1+auc2+auc3)/3)\n",
    "        AUCscores[x] = score\n",
    "        \n",
    "all_values = AOscores.values()\n",
    "max_value = max(all_values)\n",
    "max_key = max(AOscores, key=AOscores.get)\n",
    "print('Optimal OA parameter ' + str(max_key) + str(max_value))\n",
    "\n",
    "all_values1 = Pscores.values()\n",
    "max_value1 = max(all_values1)\n",
    "max_key1 = max(Pscores, key=Pscores.get)\n",
    "print('Optimal P parameter ' + str(max_key1) + str(max_value1))\n",
    "\n",
    "all_values2 = Rscores.values()\n",
    "max_value2 = max(all_values2)\n",
    "max_key2 = max(Rscores, key=Rscores.get)\n",
    "print('Optimal R parameter ' + str(max_key2) + str(max_value2))\n",
    "\n",
    "all_values3 = Fscores.values()\n",
    "max_value3 = max(all_values3)\n",
    "max_key3 = max(Fscores, key=Fscores.get)\n",
    "print('Optimal F parameter ' + str(max_key3) + str(max_value3))\n",
    "\n",
    "all_values4 = AUCscores.values()\n",
    "max_value4 = max(all_values4)\n",
    "max_key4 = max(AUCscores, key=AUCscores.get)\n",
    "print('Optimal AUC parameter ' + str(max_key4) + str(max_value4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f026081b",
   "metadata": {},
   "source": [
    "## IF mmi sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e439148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal OA parameter 110.30.7117233071788652\n",
      "Optimal P parameter 120.70.7586016286469287\n",
      "Optimal R parameter 80.30.9810309253431536\n",
      "Optimal F parameter 110.30.7733597754610605\n",
      "Optimal AUC parameter 70.70.735367636007235\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#IF\n",
    "estimators = [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
    "threshold = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "AOscores = {}\n",
    "Pscores = {}\n",
    "Rscores ={}\n",
    "Fscores = {}\n",
    "AUCscores = {}\n",
    "\n",
    "\n",
    "for e in estimators:\n",
    "    for t in threshold:\n",
    "        x = str(e+t)\n",
    "        img = read_data_EMP(mmisub)\n",
    "        stack = np.concatenate((img, EMPmm, GLCMmm), axis=2)\n",
    "        stacked = np.dstack((stack, NDVImm, NDWImm))\n",
    "        #Setup for IF and OCSVM\n",
    "        X = stacked\n",
    "        Ytr1 = Twitm\n",
    "        nr,nc,nb = X.shape\n",
    "        ns = nr*nc\n",
    "        X = X.reshape((ns,nb))\n",
    "        Ytr = Ytr1.reshape((ns,))\n",
    "        ind = np.where(Ytr > 0)\n",
    "        Xtr = X[ind[0],:]\n",
    "        Ytr = Ytr[ind[0]]\n",
    "        standard_scaler = StandardScaler()\n",
    "        Xtr = standard_scaler.fit_transform(Xtr) \n",
    "        X = standard_scaler.transform(X)\n",
    "        model = IsolationForest(n_estimators = e)\n",
    "        model.fit(Xtr)\n",
    "        yhat = model.score_samples(X)\n",
    "        yhat1 = (yhat-min(yhat))/(max(yhat)-min(yhat))\n",
    "        class_map1 = np.reshape(yhat1,(nr,nc))\n",
    "        class_map = np.where(class_map1>t, 1, 0)\n",
    "        class_map = class_map.flatten()\n",
    "        pred = class_map\n",
    "        true1 = Val30mm\n",
    "        true2 = Val2GAIAm\n",
    "        true3 = Val3GHS50m\n",
    "        cfm1 = confusion_matrix(true1, pred)\n",
    "        TN1,FP1,FN1,TP1= cfm1.ravel()\n",
    "        cfm2 = confusion_matrix(true2, pred)\n",
    "        TN2,FP2,FN2,TP2= cfm2.ravel()\n",
    "        cfm3 = confusion_matrix(true3, pred)\n",
    "        TN3,FP3,FN3,TP3= cfm3.ravel()\n",
    "\n",
    "        AO = (((TP1+TN1)/(TP1+TN1+FP1+FN1))+\n",
    "              ((TP2+TN2)/(TP2+TN2+FP2+FN2))+\n",
    "              ((TP3+TN3)/(TP3+TN3+FP3+FN3)))/3\n",
    "        AOscores[x] = AO\n",
    "        \n",
    "        P = ((TP1/(TP1+FP1))+\n",
    "             (TP2/(TP2+FP2))+\n",
    "             (TP3/(TP3+FP3)))/3\n",
    "        Pscores[x] = P\n",
    "        \n",
    "        R = ((TP1/(TP1+FN1))+\n",
    "             (TP2/(TP2+FN2))+\n",
    "             (TP3/(TP3+FN3)))/3\n",
    "        Rscores[x] = R\n",
    "        \n",
    "        F = (((2*TP1)/(2*TP1+FP1+FN1))+\n",
    "             ((2*TP2)/(2*TP2+FP2+FN2))+\n",
    "             ((2*TP3)/(2*TP3+FP3+FN3)))/3\n",
    "        Fscores[x] = F\n",
    "        \n",
    "        auc1 = roc_auc_score(true1,pred)\n",
    "        auc2 = roc_auc_score(true2,pred)\n",
    "        auc3 = roc_auc_score(true3,pred)\n",
    "        score = ((auc1+auc2+auc3)/3)\n",
    "        AUCscores[x] = score\n",
    "        \n",
    "all_values = AOscores.values()\n",
    "max_value = max(all_values)\n",
    "max_key = max(AOscores, key=AOscores.get)\n",
    "print('Optimal OA parameter ' + str(max_key) + str(max_value))\n",
    "\n",
    "all_values1 = Pscores.values()\n",
    "max_value1 = max(all_values1)\n",
    "max_key1 = max(Pscores, key=Pscores.get)\n",
    "print('Optimal P parameter ' + str(max_key1) + str(max_value1))\n",
    "\n",
    "all_values2 = Rscores.values()\n",
    "max_value2 = max(all_values2)\n",
    "max_key2 = max(Rscores, key=Rscores.get)\n",
    "print('Optimal R parameter ' + str(max_key2) + str(max_value2))\n",
    "\n",
    "all_values3 = Fscores.values()\n",
    "max_value3 = max(all_values3)\n",
    "max_key3 = max(Fscores, key=Fscores.get)\n",
    "print('Optimal F parameter ' + str(max_key3) + str(max_value3))\n",
    "\n",
    "all_values4 = AUCscores.values()\n",
    "max_value4 = max(all_values4)\n",
    "max_key4 = max(AUCscores, key=AUCscores.get)\n",
    "print('Optimal AUC parameter ' + str(max_key4) + str(max_value4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334d6d21",
   "metadata": {},
   "source": [
    "## IF bsi sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e3c2463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal OA parameter 90.60.7550720691732052\n",
      "Optimal P parameter 60.70.7704216266932504\n",
      "Optimal R parameter 110.30.9789812976517099\n",
      "Optimal F parameter 50.60.7397899560505575\n",
      "Optimal AUC parameter 90.60.7874621370780197\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#IF\n",
    "estimators = [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
    "threshold = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "AOscores = {}\n",
    "Pscores = {}\n",
    "Rscores ={}\n",
    "Fscores = {}\n",
    "AUCscores = {}\n",
    "\n",
    "\n",
    "for e in estimators:\n",
    "    for t in threshold:\n",
    "        x = str(e+t)\n",
    "        img = read_data_EMP(bsisub)\n",
    "        stack = np.concatenate((img, EMPbs, GLCMbs), axis=2)\n",
    "        stacked = np.dstack((stack, NDVIbs, NDWIbs))\n",
    "        #Setup for IF and OCSVM\n",
    "        X = stacked\n",
    "        Ytr1 = Twitb\n",
    "        nr,nc,nb = X.shape\n",
    "        ns = nr*nc\n",
    "        X = X.reshape((ns,nb))\n",
    "        Ytr = Ytr1.reshape((ns,))\n",
    "        ind = np.where(Ytr > 0)\n",
    "        Xtr = X[ind[0],:]\n",
    "        Ytr = Ytr[ind[0]]\n",
    "        standard_scaler = StandardScaler()\n",
    "        Xtr = standard_scaler.fit_transform(Xtr) \n",
    "        X = standard_scaler.transform(X)\n",
    "        model = IsolationForest(n_estimators = e)\n",
    "        model.fit(Xtr)\n",
    "        yhat = model.score_samples(X)\n",
    "        yhat1 = (yhat-min(yhat))/(max(yhat)-min(yhat))\n",
    "        class_map1 = np.reshape(yhat1,(nr,nc))\n",
    "        class_map = np.where(class_map1>t, 1, 0)\n",
    "        class_map = class_map.flatten()\n",
    "        pred = class_map\n",
    "        true1 = Val30mb\n",
    "        true2 = Val2GAIAb\n",
    "        true3 = Val3GHS50b\n",
    "        cfm1 = confusion_matrix(true1, pred)\n",
    "        TN1,FP1,FN1,TP1= cfm1.ravel()\n",
    "        cfm2 = confusion_matrix(true2, pred)\n",
    "        TN2,FP2,FN2,TP2= cfm2.ravel()\n",
    "        cfm3 = confusion_matrix(true3, pred)\n",
    "        TN3,FP3,FN3,TP3= cfm3.ravel()\n",
    "\n",
    "        AO = (((TP1+TN1)/(TP1+TN1+FP1+FN1))+\n",
    "              ((TP2+TN2)/(TP2+TN2+FP2+FN2))+\n",
    "              ((TP3+TN3)/(TP3+TN3+FP3+FN3)))/3\n",
    "        AOscores[x] = AO\n",
    "        \n",
    "        P = ((TP1/(TP1+FP1))+\n",
    "             (TP2/(TP2+FP2))+\n",
    "             (TP3/(TP3+FP3)))/3\n",
    "        Pscores[x] = P\n",
    "        \n",
    "        R = ((TP1/(TP1+FN1))+\n",
    "             (TP2/(TP2+FN2))+\n",
    "             (TP3/(TP3+FN3)))/3\n",
    "        Rscores[x] = R\n",
    "        \n",
    "        F = (((2*TP1)/(2*TP1+FP1+FN1))+\n",
    "             ((2*TP2)/(2*TP2+FP2+FN2))+\n",
    "             ((2*TP3)/(2*TP3+FP3+FN3)))/3\n",
    "        Fscores[x] = F\n",
    "        \n",
    "        auc1 = roc_auc_score(true1,pred)\n",
    "        auc2 = roc_auc_score(true2,pred)\n",
    "        auc3 = roc_auc_score(true3,pred)\n",
    "        score = ((auc1+auc2+auc3)/3)\n",
    "        AUCscores[x] = score\n",
    "        \n",
    "all_values = AOscores.values()\n",
    "max_value = max(all_values)\n",
    "max_key = max(AOscores, key=AOscores.get)\n",
    "print('Optimal OA parameter ' + str(max_key) + str(max_value))\n",
    "\n",
    "all_values1 = Pscores.values()\n",
    "max_value1 = max(all_values1)\n",
    "max_key1 = max(Pscores, key=Pscores.get)\n",
    "print('Optimal P parameter ' + str(max_key1) + str(max_value1))\n",
    "\n",
    "all_values2 = Rscores.values()\n",
    "max_value2 = max(all_values2)\n",
    "max_key2 = max(Rscores, key=Rscores.get)\n",
    "print('Optimal R parameter ' + str(max_key2) + str(max_value2))\n",
    "\n",
    "all_values3 = Fscores.values()\n",
    "max_value3 = max(all_values3)\n",
    "max_key3 = max(Fscores, key=Fscores.get)\n",
    "print('Optimal F parameter ' + str(max_key3) + str(max_value3))\n",
    "\n",
    "all_values4 = AUCscores.values()\n",
    "max_value4 = max(all_values4)\n",
    "max_key4 = max(AUCscores, key=AUCscores.get)\n",
    "print('Optimal AUC parameter ' + str(max_key4) + str(max_value4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a79c2a",
   "metadata": {},
   "source": [
    "## IF bmi sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3de07eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal OA parameter 50.60.7591313746359414\n",
      "Optimal P parameter 80.70.7929817767163665\n",
      "Optimal R parameter 60.30.967972046899637\n",
      "Optimal F parameter 70.50.7440820939834762\n",
      "Optimal AUC parameter 50.60.7914763375678356\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#IF\n",
    "estimators = [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
    "threshold = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "AOscores = {}\n",
    "Pscores = {}\n",
    "Rscores ={}\n",
    "Fscores = {}\n",
    "AUCscores = {}\n",
    "\n",
    "\n",
    "for e in estimators:\n",
    "    for t in threshold:\n",
    "        x = str(e+t)\n",
    "        img = read_data_EMP(bmisub)\n",
    "        stack = np.concatenate((img, EMPbm, GLCMbm), axis=2)\n",
    "        stacked = np.dstack((stack, NDVIbm, NDWIbm))\n",
    "        #Setup for IF and OCSVM\n",
    "        X = stacked\n",
    "        Ytr1 = Twitb\n",
    "        nr,nc,nb = X.shape\n",
    "        ns = nr*nc\n",
    "        X = X.reshape((ns,nb))\n",
    "        Ytr = Ytr1.reshape((ns,))\n",
    "        ind = np.where(Ytr > 0)\n",
    "        Xtr = X[ind[0],:]\n",
    "        Ytr = Ytr[ind[0]]\n",
    "        standard_scaler = StandardScaler()\n",
    "        Xtr = standard_scaler.fit_transform(Xtr) \n",
    "        X = standard_scaler.transform(X)\n",
    "        model = IsolationForest(n_estimators = e)\n",
    "        model.fit(Xtr)\n",
    "        yhat = model.score_samples(X)\n",
    "        yhat1 = (yhat-min(yhat))/(max(yhat)-min(yhat))\n",
    "        class_map1 = np.reshape(yhat1,(nr,nc))\n",
    "        class_map = np.where(class_map1>t, 1, 0)\n",
    "        class_map = class_map.flatten()\n",
    "        pred = class_map\n",
    "        true1 = Val30mb\n",
    "        true2 = Val2GAIAb\n",
    "        true3 = Val3GHS50b\n",
    "        cfm1 = confusion_matrix(true1, pred)\n",
    "        TN1,FP1,FN1,TP1= cfm1.ravel()\n",
    "        cfm2 = confusion_matrix(true2, pred)\n",
    "        TN2,FP2,FN2,TP2= cfm2.ravel()\n",
    "        cfm3 = confusion_matrix(true3, pred)\n",
    "        TN3,FP3,FN3,TP3= cfm3.ravel()\n",
    "\n",
    "        AO = (((TP1+TN1)/(TP1+TN1+FP1+FN1))+\n",
    "              ((TP2+TN2)/(TP2+TN2+FP2+FN2))+\n",
    "              ((TP3+TN3)/(TP3+TN3+FP3+FN3)))/3\n",
    "        AOscores[x] = AO\n",
    "        \n",
    "        P = ((TP1/(TP1+FP1))+\n",
    "             (TP2/(TP2+FP2))+\n",
    "             (TP3/(TP3+FP3)))/3\n",
    "        Pscores[x] = P\n",
    "        \n",
    "        R = ((TP1/(TP1+FN1))+\n",
    "             (TP2/(TP2+FN2))+\n",
    "             (TP3/(TP3+FN3)))/3\n",
    "        Rscores[x] = R\n",
    "        \n",
    "        F = (((2*TP1)/(2*TP1+FP1+FN1))+\n",
    "             ((2*TP2)/(2*TP2+FP2+FN2))+\n",
    "             ((2*TP3)/(2*TP3+FP3+FN3)))/3\n",
    "        Fscores[x] = F\n",
    "        \n",
    "        auc1 = roc_auc_score(true1,pred)\n",
    "        auc2 = roc_auc_score(true2,pred)\n",
    "        auc3 = roc_auc_score(true3,pred)\n",
    "        score = ((auc1+auc2+auc3)/3)\n",
    "        AUCscores[x] = score\n",
    "        \n",
    "all_values = AOscores.values()\n",
    "max_value = max(all_values)\n",
    "max_key = max(AOscores, key=AOscores.get)\n",
    "print('Optimal OA parameter ' + str(max_key) + str(max_value))\n",
    "\n",
    "all_values1 = Pscores.values()\n",
    "max_value1 = max(all_values1)\n",
    "max_key1 = max(Pscores, key=Pscores.get)\n",
    "print('Optimal P parameter ' + str(max_key1) + str(max_value1))\n",
    "\n",
    "all_values2 = Rscores.values()\n",
    "max_value2 = max(all_values2)\n",
    "max_key2 = max(Rscores, key=Rscores.get)\n",
    "print('Optimal R parameter ' + str(max_key2) + str(max_value2))\n",
    "\n",
    "all_values3 = Fscores.values()\n",
    "max_value3 = max(all_values3)\n",
    "max_key3 = max(Fscores, key=Fscores.get)\n",
    "print('Optimal F parameter ' + str(max_key3) + str(max_value3))\n",
    "\n",
    "all_values4 = AUCscores.values()\n",
    "max_value4 = max(all_values4)\n",
    "max_key4 = max(AUCscores, key=AUCscores.get)\n",
    "print('Optimal AUC parameter ' + str(max_key4) + str(max_value4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5972114d",
   "metadata": {},
   "source": [
    "## SVM asi sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "951b4bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal OA parameter rbf0.50.4_0.6865754147999636\n",
      "Optimal P parameter rbf0.70.7_0.7142109737754234\n",
      "Optimal R parameter linear0.20.3_0.9996409466038322\n",
      "Optimal F parameter rbf0.40.3_0.6667870119162295\n",
      "Optimal AUC parameter rbf0.50.4_0.7335126853205396\n",
      "Wall time: 9.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#IF\n",
    "kernel = [\"rbf\", \"linear\"]\n",
    "nu = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "threshold = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "AOscores = {}\n",
    "Pscores = {}\n",
    "Rscores ={}\n",
    "Fscores = {}\n",
    "AUCscores = {}\n",
    "\n",
    "\n",
    "for k in kernel:\n",
    "    for n in nu:\n",
    "        for t in threshold:\n",
    "            x = str(k)+str(n)+str(t)\n",
    "            img = read_data_EMP(asisub)\n",
    "            stack = np.concatenate((img, EMPas, GLCMas), axis=2)\n",
    "            stacked = np.dstack((stack, NDVIas, NDWIas))\n",
    "            #Setup for IF and OCSVM\n",
    "            X = stacked\n",
    "            Ytr1 = Twita\n",
    "            nr,nc,nb = X.shape\n",
    "            ns = nr*nc\n",
    "            X = X.reshape((ns,nb))\n",
    "            Ytr = Ytr1.reshape((ns,))\n",
    "            ind = np.where(Ytr > 0)\n",
    "            Xtr = X[ind[0],:]\n",
    "            Ytr = Ytr[ind[0]]\n",
    "            standard_scaler = StandardScaler()\n",
    "            Xtr = standard_scaler.fit_transform(Xtr) \n",
    "            X = standard_scaler.transform(X)\n",
    "            model = svm.OneClassSVM(nu=n, kernel=k)\n",
    "            model.fit(Xtr)\n",
    "            yhat = model.score_samples(X)\n",
    "            yhat1 = (yhat-min(yhat))/(max(yhat)-min(yhat))\n",
    "            class_map1 = np.reshape(yhat1,(nr,nc))\n",
    "            class_map = np.where(class_map1>t, 1, 0)\n",
    "            class_map = class_map.flatten()\n",
    "            pred = class_map\n",
    "            true1 = Val30ma\n",
    "            true2 = Val2GAIAa\n",
    "            true3 = Val3GHS50a\n",
    "            cfm1 = confusion_matrix(true1, pred)\n",
    "            TN1,FP1,FN1,TP1= cfm1.ravel()\n",
    "            cfm2 = confusion_matrix(true2, pred)\n",
    "            TN2,FP2,FN2,TP2= cfm2.ravel()\n",
    "            cfm3 = confusion_matrix(true3, pred)\n",
    "            TN3,FP3,FN3,TP3= cfm3.ravel()\n",
    "\n",
    "            AO = (((TP1+TN1)/(TP1+TN1+FP1+FN1))+\n",
    "                  ((TP2+TN2)/(TP2+TN2+FP2+FN2))+\n",
    "                  ((TP3+TN3)/(TP3+TN3+FP3+FN3)))/3\n",
    "            AOscores[x] = AO\n",
    "        \n",
    "            P = ((TP1/(TP1+FP1))+\n",
    "                 (TP2/(TP2+FP2))+\n",
    "                 (TP3/(TP3+FP3)))/3\n",
    "            Pscores[x] = P\n",
    "        \n",
    "            R = ((TP1/(TP1+FN1))+\n",
    "                 (TP2/(TP2+FN2))+\n",
    "                 (TP3/(TP3+FN3)))/3\n",
    "            Rscores[x] = R\n",
    "        \n",
    "            F = (((2*TP1)/(2*TP1+FP1+FN1))+\n",
    "                 ((2*TP2)/(2*TP2+FP2+FN2))+\n",
    "                 ((2*TP3)/(2*TP3+FP3+FN3)))/3\n",
    "            Fscores[x] = F\n",
    "        \n",
    "            auc1 = roc_auc_score(true1,pred)\n",
    "            auc2 = roc_auc_score(true2,pred)\n",
    "            auc3 = roc_auc_score(true3,pred)\n",
    "            score = ((auc1+auc2+auc3)/3)\n",
    "            AUCscores[x] = score\n",
    "        \n",
    "all_values = AOscores.values()\n",
    "max_value = max(all_values)\n",
    "max_key = max(AOscores, key=AOscores.get)\n",
    "print('Optimal OA parameter ' + str(max_key) + '_' + str(max_value))\n",
    "\n",
    "all_values1 = Pscores.values()\n",
    "max_value1 = max(all_values1)\n",
    "max_key1 = max(Pscores, key=Pscores.get)\n",
    "print('Optimal P parameter ' + str(max_key1) + '_' + str(max_value1))\n",
    "\n",
    "all_values2 = Rscores.values()\n",
    "max_value2 = max(all_values2)\n",
    "max_key2 = max(Rscores, key=Rscores.get)\n",
    "print('Optimal R parameter ' + str(max_key2) + '_' + str(max_value2))\n",
    "\n",
    "all_values3 = Fscores.values()\n",
    "max_value3 = max(all_values3)\n",
    "max_key3 = max(Fscores, key=Fscores.get)\n",
    "print('Optimal F parameter ' + str(max_key3) + '_' + str(max_value3))\n",
    "\n",
    "all_values4 = AUCscores.values()\n",
    "max_value4 = max(all_values4)\n",
    "max_key4 = max(AUCscores, key=AUCscores.get)\n",
    "print('Optimal AUC parameter ' + str(max_key4) + '_' + str(max_value4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608197cc",
   "metadata": {},
   "source": [
    "## SVM ami sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca4097b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal OA parameter rbf0.40.5_0.6934976857008489\n",
      "Optimal P parameter rbf0.40.7_0.7180445680836883\n",
      "Optimal R parameter linear0.80.3_1.0\n",
      "Optimal F parameter rbf0.30.4_0.6653806525934035\n",
      "Optimal AUC parameter rbf0.40.5_0.7408354295516318\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#IF\n",
    "kernel = [\"rbf\", \"linear\"]\n",
    "nu = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "threshold = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "AOscores = {}\n",
    "Pscores = {}\n",
    "Rscores ={}\n",
    "Fscores = {}\n",
    "AUCscores = {}\n",
    "\n",
    "\n",
    "for k in kernel:\n",
    "    for n in nu:\n",
    "        for t in threshold:\n",
    "            x = str(k)+str(n)+str(t)\n",
    "            img = read_data_EMP(amisub)\n",
    "            stack = np.concatenate((img, EMPam, GLCMam), axis=2)\n",
    "            stacked = np.dstack((stack, NDVIam, NDWIam))\n",
    "            #Setup for IF and OCSVM\n",
    "            X = stacked\n",
    "            Ytr1 = Twita\n",
    "            nr,nc,nb = X.shape\n",
    "            ns = nr*nc\n",
    "            X = X.reshape((ns,nb))\n",
    "            Ytr = Ytr1.reshape((ns,))\n",
    "            ind = np.where(Ytr > 0)\n",
    "            Xtr = X[ind[0],:]\n",
    "            Ytr = Ytr[ind[0]]\n",
    "            standard_scaler = StandardScaler()\n",
    "            Xtr = standard_scaler.fit_transform(Xtr) \n",
    "            X = standard_scaler.transform(X)\n",
    "            model = svm.OneClassSVM(nu=n, kernel=k)\n",
    "            model.fit(Xtr)\n",
    "            yhat = model.score_samples(X)\n",
    "            yhat1 = (yhat-min(yhat))/(max(yhat)-min(yhat))\n",
    "            class_map1 = np.reshape(yhat1,(nr,nc))\n",
    "            class_map = np.where(class_map1>t, 1, 0)\n",
    "            class_map = class_map.flatten()\n",
    "            pred = class_map\n",
    "            true1 = Val30ma\n",
    "            true2 = Val2GAIAa\n",
    "            true3 = Val3GHS50a\n",
    "            cfm1 = confusion_matrix(true1, pred)\n",
    "            TN1,FP1,FN1,TP1= cfm1.ravel()\n",
    "            cfm2 = confusion_matrix(true2, pred)\n",
    "            TN2,FP2,FN2,TP2= cfm2.ravel()\n",
    "            cfm3 = confusion_matrix(true3, pred)\n",
    "            TN3,FP3,FN3,TP3= cfm3.ravel()\n",
    "\n",
    "            AO = (((TP1+TN1)/(TP1+TN1+FP1+FN1))+\n",
    "                  ((TP2+TN2)/(TP2+TN2+FP2+FN2))+\n",
    "                  ((TP3+TN3)/(TP3+TN3+FP3+FN3)))/3\n",
    "            AOscores[x] = AO\n",
    "        \n",
    "            P = ((TP1/(TP1+FP1))+\n",
    "                 (TP2/(TP2+FP2))+\n",
    "                 (TP3/(TP3+FP3)))/3\n",
    "            Pscores[x] = P\n",
    "        \n",
    "            R = ((TP1/(TP1+FN1))+\n",
    "                 (TP2/(TP2+FN2))+\n",
    "                 (TP3/(TP3+FN3)))/3\n",
    "            Rscores[x] = R\n",
    "        \n",
    "            F = (((2*TP1)/(2*TP1+FP1+FN1))+\n",
    "                 ((2*TP2)/(2*TP2+FP2+FN2))+\n",
    "                 ((2*TP3)/(2*TP3+FP3+FN3)))/3\n",
    "            Fscores[x] = F\n",
    "        \n",
    "            auc1 = roc_auc_score(true1,pred)\n",
    "            auc2 = roc_auc_score(true2,pred)\n",
    "            auc3 = roc_auc_score(true3,pred)\n",
    "            score = ((auc1+auc2+auc3)/3)\n",
    "            AUCscores[x] = score\n",
    "        \n",
    "all_values = AOscores.values()\n",
    "max_value = max(all_values)\n",
    "max_key = max(AOscores, key=AOscores.get)\n",
    "print('Optimal OA parameter ' + str(max_key) + '_' + str(max_value))\n",
    "\n",
    "all_values1 = Pscores.values()\n",
    "max_value1 = max(all_values1)\n",
    "max_key1 = max(Pscores, key=Pscores.get)\n",
    "print('Optimal P parameter ' + str(max_key1) + '_' + str(max_value1))\n",
    "\n",
    "all_values2 = Rscores.values()\n",
    "max_value2 = max(all_values2)\n",
    "max_key2 = max(Rscores, key=Rscores.get)\n",
    "print('Optimal R parameter ' + str(max_key2) + '_' + str(max_value2))\n",
    "\n",
    "all_values3 = Fscores.values()\n",
    "max_value3 = max(all_values3)\n",
    "max_key3 = max(Fscores, key=Fscores.get)\n",
    "print('Optimal F parameter ' + str(max_key3) + '_' + str(max_value3))\n",
    "\n",
    "all_values4 = AUCscores.values()\n",
    "max_value4 = max(all_values4)\n",
    "max_key4 = max(AUCscores, key=AUCscores.get)\n",
    "print('Optimal AUC parameter ' + str(max_key4) + '_' + str(max_value4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a477e4",
   "metadata": {},
   "source": [
    "## SVM msi sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cde9ae6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal OA parameter rbf0.30.3_0.7099824261775699\n",
      "Optimal P parameter rbf0.80.7_0.7733238315814478\n",
      "Optimal R parameter linear0.30.3_0.9954783362030489\n",
      "Optimal F parameter rbf0.30.3_0.7663062583470244\n",
      "Optimal AUC parameter rbf0.40.5_0.7481506234838319\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#IF\n",
    "kernel = [\"rbf\", \"linear\"]\n",
    "nu = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "threshold = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "AOscores = {}\n",
    "Pscores = {}\n",
    "Rscores ={}\n",
    "Fscores = {}\n",
    "AUCscores = {}\n",
    "\n",
    "\n",
    "for k in kernel:\n",
    "    for n in nu:\n",
    "        for t in threshold:\n",
    "            x = str(k)+str(n)+str(t)\n",
    "            img = read_data_EMP(msisub)\n",
    "            stack = np.concatenate((img, EMPms, GLCMms), axis=2)\n",
    "            stacked = np.dstack((stack, NDVIms, NDWIms))\n",
    "            #Setup for IF and OCSVM\n",
    "            X = stacked\n",
    "            Ytr1 = Twitm\n",
    "            nr,nc,nb = X.shape\n",
    "            ns = nr*nc\n",
    "            X = X.reshape((ns,nb))\n",
    "            Ytr = Ytr1.reshape((ns,))\n",
    "            ind = np.where(Ytr > 0)\n",
    "            Xtr = X[ind[0],:]\n",
    "            Ytr = Ytr[ind[0]]\n",
    "            standard_scaler = StandardScaler()\n",
    "            Xtr = standard_scaler.fit_transform(Xtr) \n",
    "            X = standard_scaler.transform(X)\n",
    "            model = svm.OneClassSVM(nu=n, kernel=k)\n",
    "            model.fit(Xtr)\n",
    "            yhat = model.score_samples(X)\n",
    "            yhat1 = (yhat-min(yhat))/(max(yhat)-min(yhat))\n",
    "            class_map1 = np.reshape(yhat1,(nr,nc))\n",
    "            class_map = np.where(class_map1>t, 1, 0)\n",
    "            class_map = class_map.flatten()\n",
    "            pred = class_map\n",
    "            true1 = Val30mm\n",
    "            true2 = Val2GAIAm\n",
    "            true3 = Val3GHS50m\n",
    "            cfm1 = confusion_matrix(true1, pred)\n",
    "            TN1,FP1,FN1,TP1= cfm1.ravel()\n",
    "            cfm2 = confusion_matrix(true2, pred)\n",
    "            TN2,FP2,FN2,TP2= cfm2.ravel()\n",
    "            cfm3 = confusion_matrix(true3, pred)\n",
    "            TN3,FP3,FN3,TP3= cfm3.ravel()\n",
    "\n",
    "            AO = (((TP1+TN1)/(TP1+TN1+FP1+FN1))+\n",
    "                  ((TP2+TN2)/(TP2+TN2+FP2+FN2))+\n",
    "                  ((TP3+TN3)/(TP3+TN3+FP3+FN3)))/3\n",
    "            AOscores[x] = AO\n",
    "        \n",
    "            P = ((TP1/(TP1+FP1))+\n",
    "                 (TP2/(TP2+FP2))+\n",
    "                 (TP3/(TP3+FP3)))/3\n",
    "            Pscores[x] = P\n",
    "        \n",
    "            R = ((TP1/(TP1+FN1))+\n",
    "                 (TP2/(TP2+FN2))+\n",
    "                 (TP3/(TP3+FN3)))/3\n",
    "            Rscores[x] = R\n",
    "        \n",
    "            F = (((2*TP1)/(2*TP1+FP1+FN1))+\n",
    "                 ((2*TP2)/(2*TP2+FP2+FN2))+\n",
    "                 ((2*TP3)/(2*TP3+FP3+FN3)))/3\n",
    "            Fscores[x] = F\n",
    "        \n",
    "            auc1 = roc_auc_score(true1,pred)\n",
    "            auc2 = roc_auc_score(true2,pred)\n",
    "            auc3 = roc_auc_score(true3,pred)\n",
    "            score = ((auc1+auc2+auc3)/3)\n",
    "            AUCscores[x] = score\n",
    "        \n",
    "all_values = AOscores.values()\n",
    "max_value = max(all_values)\n",
    "max_key = max(AOscores, key=AOscores.get)\n",
    "print('Optimal OA parameter ' + str(max_key) + '_' + str(max_value))\n",
    "\n",
    "all_values1 = Pscores.values()\n",
    "max_value1 = max(all_values1)\n",
    "max_key1 = max(Pscores, key=Pscores.get)\n",
    "print('Optimal P parameter ' + str(max_key1) + '_' + str(max_value1))\n",
    "\n",
    "all_values2 = Rscores.values()\n",
    "max_value2 = max(all_values2)\n",
    "max_key2 = max(Rscores, key=Rscores.get)\n",
    "print('Optimal R parameter ' + str(max_key2) + '_' + str(max_value2))\n",
    "\n",
    "all_values3 = Fscores.values()\n",
    "max_value3 = max(all_values3)\n",
    "max_key3 = max(Fscores, key=Fscores.get)\n",
    "print('Optimal F parameter ' + str(max_key3) + '_' + str(max_value3))\n",
    "\n",
    "all_values4 = AUCscores.values()\n",
    "max_value4 = max(all_values4)\n",
    "max_key4 = max(AUCscores, key=AUCscores.get)\n",
    "print('Optimal AUC parameter ' + str(max_key4) + '_' + str(max_value4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77aab11",
   "metadata": {},
   "source": [
    "## SVM mmi sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "739b4ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal OA parameter rbf0.20.4_0.7168056896281444\n",
      "Optimal P parameter rbf0.80.7_0.7692093302461195\n",
      "Optimal R parameter linear0.70.3_0.999079899521881\n",
      "Optimal F parameter rbf0.20.3_0.7707072120605912\n",
      "Optimal AUC parameter rbf0.50.4_0.7494396926147445\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#IF\n",
    "kernel = [\"rbf\", \"linear\"]\n",
    "nu = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "threshold = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "AOscores = {}\n",
    "Pscores = {}\n",
    "Rscores ={}\n",
    "Fscores = {}\n",
    "AUCscores = {}\n",
    "\n",
    "\n",
    "for k in kernel:\n",
    "    for n in nu:\n",
    "        for t in threshold:\n",
    "            x = str(k)+str(n)+str(t)\n",
    "            img = read_data_EMP(mmisub)\n",
    "            stack = np.concatenate((img, EMPmm, GLCMmm), axis=2)\n",
    "            stacked = np.dstack((stack, NDVImm, NDWImm))\n",
    "            #Setup for IF and OCSVM\n",
    "            X = stacked\n",
    "            Ytr1 = Twitm\n",
    "            nr,nc,nb = X.shape\n",
    "            ns = nr*nc\n",
    "            X = X.reshape((ns,nb))\n",
    "            Ytr = Ytr1.reshape((ns,))\n",
    "            ind = np.where(Ytr > 0)\n",
    "            Xtr = X[ind[0],:]\n",
    "            Ytr = Ytr[ind[0]]\n",
    "            standard_scaler = StandardScaler()\n",
    "            Xtr = standard_scaler.fit_transform(Xtr) \n",
    "            X = standard_scaler.transform(X)\n",
    "            model = svm.OneClassSVM(nu=n, kernel=k)\n",
    "            model.fit(Xtr)\n",
    "            yhat = model.score_samples(X)\n",
    "            yhat1 = (yhat-min(yhat))/(max(yhat)-min(yhat))\n",
    "            class_map1 = np.reshape(yhat1,(nr,nc))\n",
    "            class_map = np.where(class_map1>t, 1, 0)\n",
    "            class_map = class_map.flatten()\n",
    "            pred = class_map\n",
    "            true1 = Val30mm\n",
    "            true2 = Val2GAIAm\n",
    "            true3 = Val3GHS50m\n",
    "            cfm1 = confusion_matrix(true1, pred)\n",
    "            TN1,FP1,FN1,TP1= cfm1.ravel()\n",
    "            cfm2 = confusion_matrix(true2, pred)\n",
    "            TN2,FP2,FN2,TP2= cfm2.ravel()\n",
    "            cfm3 = confusion_matrix(true3, pred)\n",
    "            TN3,FP3,FN3,TP3= cfm3.ravel()\n",
    "\n",
    "            AO = (((TP1+TN1)/(TP1+TN1+FP1+FN1))+\n",
    "                  ((TP2+TN2)/(TP2+TN2+FP2+FN2))+\n",
    "                  ((TP3+TN3)/(TP3+TN3+FP3+FN3)))/3\n",
    "            AOscores[x] = AO\n",
    "        \n",
    "            P = ((TP1/(TP1+FP1))+\n",
    "                 (TP2/(TP2+FP2))+\n",
    "                 (TP3/(TP3+FP3)))/3\n",
    "            Pscores[x] = P\n",
    "        \n",
    "            R = ((TP1/(TP1+FN1))+\n",
    "                 (TP2/(TP2+FN2))+\n",
    "                 (TP3/(TP3+FN3)))/3\n",
    "            Rscores[x] = R\n",
    "        \n",
    "            F = (((2*TP1)/(2*TP1+FP1+FN1))+\n",
    "                 ((2*TP2)/(2*TP2+FP2+FN2))+\n",
    "                 ((2*TP3)/(2*TP3+FP3+FN3)))/3\n",
    "            Fscores[x] = F\n",
    "        \n",
    "            auc1 = roc_auc_score(true1,pred)\n",
    "            auc2 = roc_auc_score(true2,pred)\n",
    "            auc3 = roc_auc_score(true3,pred)\n",
    "            score = ((auc1+auc2+auc3)/3)\n",
    "            AUCscores[x] = score\n",
    "        \n",
    "all_values = AOscores.values()\n",
    "max_value = max(all_values)\n",
    "max_key = max(AOscores, key=AOscores.get)\n",
    "print('Optimal OA parameter ' + str(max_key) + '_' + str(max_value))\n",
    "\n",
    "all_values1 = Pscores.values()\n",
    "max_value1 = max(all_values1)\n",
    "max_key1 = max(Pscores, key=Pscores.get)\n",
    "print('Optimal P parameter ' + str(max_key1) + '_' + str(max_value1))\n",
    "\n",
    "all_values2 = Rscores.values()\n",
    "max_value2 = max(all_values2)\n",
    "max_key2 = max(Rscores, key=Rscores.get)\n",
    "print('Optimal R parameter ' + str(max_key2) + '_' + str(max_value2))\n",
    "\n",
    "all_values3 = Fscores.values()\n",
    "max_value3 = max(all_values3)\n",
    "max_key3 = max(Fscores, key=Fscores.get)\n",
    "print('Optimal F parameter ' + str(max_key3) + '_' + str(max_value3))\n",
    "\n",
    "all_values4 = AUCscores.values()\n",
    "max_value4 = max(all_values4)\n",
    "max_key4 = max(AUCscores, key=AUCscores.get)\n",
    "print('Optimal AUC parameter ' + str(max_key4) + '_' + str(max_value4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec30a0",
   "metadata": {},
   "source": [
    "## SVM bsi sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c710ffe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal OA parameter rbf0.20.5_0.7304687177710122\n",
      "Optimal P parameter rbf0.80.7_0.78658857798023\n",
      "Optimal R parameter linear0.80.3_0.9951753799405391\n",
      "Optimal F parameter rbf0.30.3_0.7193181386103445\n",
      "Optimal AUC parameter rbf0.20.5_0.7590148622825885\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#IF\n",
    "kernel = [\"rbf\", \"linear\"]\n",
    "nu = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "threshold = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "AOscores = {}\n",
    "Pscores = {}\n",
    "Rscores ={}\n",
    "Fscores = {}\n",
    "AUCscores = {}\n",
    "\n",
    "\n",
    "for k in kernel:\n",
    "    for n in nu:\n",
    "        for t in threshold:\n",
    "            x = str(k)+str(n)+str(t)\n",
    "            img = read_data_EMP(bsisub)\n",
    "            stack = np.concatenate((img, EMPbs, GLCMbs), axis=2)\n",
    "            stacked = np.dstack((stack, NDVIbs, NDWIbs))\n",
    "            #Setup for IF and OCSVM\n",
    "            X = stacked\n",
    "            Ytr1 = Twitb\n",
    "            nr,nc,nb = X.shape\n",
    "            ns = nr*nc\n",
    "            X = X.reshape((ns,nb))\n",
    "            Ytr = Ytr1.reshape((ns,))\n",
    "            ind = np.where(Ytr > 0)\n",
    "            Xtr = X[ind[0],:]\n",
    "            Ytr = Ytr[ind[0]]\n",
    "            standard_scaler = StandardScaler()\n",
    "            Xtr = standard_scaler.fit_transform(Xtr) \n",
    "            X = standard_scaler.transform(X)\n",
    "            model = svm.OneClassSVM(nu=n, kernel=k)\n",
    "            model.fit(Xtr)\n",
    "            yhat = model.score_samples(X)\n",
    "            yhat1 = (yhat-min(yhat))/(max(yhat)-min(yhat))\n",
    "            class_map1 = np.reshape(yhat1,(nr,nc))\n",
    "            class_map = np.where(class_map1>t, 1, 0)\n",
    "            class_map = class_map.flatten()\n",
    "            pred = class_map\n",
    "            true1 = Val30mb\n",
    "            true2 = Val2GAIAb\n",
    "            true3 = Val3GHS50b\n",
    "            cfm1 = confusion_matrix(true1, pred)\n",
    "            TN1,FP1,FN1,TP1= cfm1.ravel()\n",
    "            cfm2 = confusion_matrix(true2, pred)\n",
    "            TN2,FP2,FN2,TP2= cfm2.ravel()\n",
    "            cfm3 = confusion_matrix(true3, pred)\n",
    "            TN3,FP3,FN3,TP3= cfm3.ravel()\n",
    "\n",
    "            AO = (((TP1+TN1)/(TP1+TN1+FP1+FN1))+\n",
    "                  ((TP2+TN2)/(TP2+TN2+FP2+FN2))+\n",
    "                  ((TP3+TN3)/(TP3+TN3+FP3+FN3)))/3\n",
    "            AOscores[x] = AO\n",
    "        \n",
    "            P = ((TP1/(TP1+FP1))+\n",
    "                 (TP2/(TP2+FP2))+\n",
    "                 (TP3/(TP3+FP3)))/3\n",
    "            Pscores[x] = P\n",
    "        \n",
    "            R = ((TP1/(TP1+FN1))+\n",
    "                 (TP2/(TP2+FN2))+\n",
    "                 (TP3/(TP3+FN3)))/3\n",
    "            Rscores[x] = R\n",
    "        \n",
    "            F = (((2*TP1)/(2*TP1+FP1+FN1))+\n",
    "                 ((2*TP2)/(2*TP2+FP2+FN2))+\n",
    "                 ((2*TP3)/(2*TP3+FP3+FN3)))/3\n",
    "            Fscores[x] = F\n",
    "        \n",
    "            auc1 = roc_auc_score(true1,pred)\n",
    "            auc2 = roc_auc_score(true2,pred)\n",
    "            auc3 = roc_auc_score(true3,pred)\n",
    "            score = ((auc1+auc2+auc3)/3)\n",
    "            AUCscores[x] = score\n",
    "        \n",
    "all_values = AOscores.values()\n",
    "max_value = max(all_values)\n",
    "max_key = max(AOscores, key=AOscores.get)\n",
    "print('Optimal OA parameter ' + str(max_key) + '_' + str(max_value))\n",
    "\n",
    "all_values1 = Pscores.values()\n",
    "max_value1 = max(all_values1)\n",
    "max_key1 = max(Pscores, key=Pscores.get)\n",
    "print('Optimal P parameter ' + str(max_key1) + '_' + str(max_value1))\n",
    "\n",
    "all_values2 = Rscores.values()\n",
    "max_value2 = max(all_values2)\n",
    "max_key2 = max(Rscores, key=Rscores.get)\n",
    "print('Optimal R parameter ' + str(max_key2) + '_' + str(max_value2))\n",
    "\n",
    "all_values3 = Fscores.values()\n",
    "max_value3 = max(all_values3)\n",
    "max_key3 = max(Fscores, key=Fscores.get)\n",
    "print('Optimal F parameter ' + str(max_key3) + '_' + str(max_value3))\n",
    "\n",
    "all_values4 = AUCscores.values()\n",
    "max_value4 = max(all_values4)\n",
    "max_key4 = max(AUCscores, key=AUCscores.get)\n",
    "print('Optimal AUC parameter ' + str(max_key4) + '_' + str(max_value4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc26f01",
   "metadata": {},
   "source": [
    "## SVM bmi sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "676bd22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal OA parameter rbf0.70.4_0.7386945867676543\n",
      "Optimal P parameter rbf0.80.7_0.8179849054049481\n",
      "Optimal R parameter linear0.40.3_0.986907265787022\n",
      "Optimal F parameter rbf0.30.3_0.7198412283090714\n",
      "Optimal AUC parameter rbf0.80.3_0.7683536262292471\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#IF\n",
    "kernel = [\"rbf\", \"linear\"]\n",
    "nu = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "threshold = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "AOscores = {}\n",
    "Pscores = {}\n",
    "Rscores ={}\n",
    "Fscores = {}\n",
    "AUCscores = {}\n",
    "\n",
    "\n",
    "for k in kernel:\n",
    "    for n in nu:\n",
    "        for t in threshold:\n",
    "            x = str(k)+str(n)+str(t)\n",
    "            img = read_data_EMP(bmisub)\n",
    "            stack = np.concatenate((img, EMPbm, GLCMbm), axis=2)\n",
    "            stacked = np.dstack((stack, NDVIbm, NDWIbm))\n",
    "            #Setup for IF and OCSVM\n",
    "            X = stacked\n",
    "            Ytr1 = Twitb\n",
    "            nr,nc,nb = X.shape\n",
    "            ns = nr*nc\n",
    "            X = X.reshape((ns,nb))\n",
    "            Ytr = Ytr1.reshape((ns,))\n",
    "            ind = np.where(Ytr > 0)\n",
    "            Xtr = X[ind[0],:]\n",
    "            Ytr = Ytr[ind[0]]\n",
    "            standard_scaler = StandardScaler()\n",
    "            Xtr = standard_scaler.fit_transform(Xtr) \n",
    "            X = standard_scaler.transform(X)\n",
    "            model = svm.OneClassSVM(nu=n, kernel=k)\n",
    "            model.fit(Xtr)\n",
    "            yhat = model.score_samples(X)\n",
    "            yhat1 = (yhat-min(yhat))/(max(yhat)-min(yhat))\n",
    "            class_map1 = np.reshape(yhat1,(nr,nc))\n",
    "            class_map = np.where(class_map1>t, 1, 0)\n",
    "            class_map = class_map.flatten()\n",
    "            pred = class_map\n",
    "            true1 = Val30mb\n",
    "            true2 = Val2GAIAb\n",
    "            true3 = Val3GHS50b\n",
    "            cfm1 = confusion_matrix(true1, pred)\n",
    "            TN1,FP1,FN1,TP1= cfm1.ravel()\n",
    "            cfm2 = confusion_matrix(true2, pred)\n",
    "            TN2,FP2,FN2,TP2= cfm2.ravel()\n",
    "            cfm3 = confusion_matrix(true3, pred)\n",
    "            TN3,FP3,FN3,TP3= cfm3.ravel()\n",
    "\n",
    "            AO = (((TP1+TN1)/(TP1+TN1+FP1+FN1))+\n",
    "                  ((TP2+TN2)/(TP2+TN2+FP2+FN2))+\n",
    "                  ((TP3+TN3)/(TP3+TN3+FP3+FN3)))/3\n",
    "            AOscores[x] = AO\n",
    "        \n",
    "            P = ((TP1/(TP1+FP1))+\n",
    "                 (TP2/(TP2+FP2))+\n",
    "                 (TP3/(TP3+FP3)))/3\n",
    "            Pscores[x] = P\n",
    "        \n",
    "            R = ((TP1/(TP1+FN1))+\n",
    "                 (TP2/(TP2+FN2))+\n",
    "                 (TP3/(TP3+FN3)))/3\n",
    "            Rscores[x] = R\n",
    "        \n",
    "            F = (((2*TP1)/(2*TP1+FP1+FN1))+\n",
    "                 ((2*TP2)/(2*TP2+FP2+FN2))+\n",
    "                 ((2*TP3)/(2*TP3+FP3+FN3)))/3\n",
    "            Fscores[x] = F\n",
    "        \n",
    "            auc1 = roc_auc_score(true1,pred)\n",
    "            auc2 = roc_auc_score(true2,pred)\n",
    "            auc3 = roc_auc_score(true3,pred)\n",
    "            score = ((auc1+auc2+auc3)/3)\n",
    "            AUCscores[x] = score\n",
    "        \n",
    "all_values = AOscores.values()\n",
    "max_value = max(all_values)\n",
    "max_key = max(AOscores, key=AOscores.get)\n",
    "print('Optimal OA parameter ' + str(max_key) + '_' + str(max_value))\n",
    "\n",
    "all_values1 = Pscores.values()\n",
    "max_value1 = max(all_values1)\n",
    "max_key1 = max(Pscores, key=Pscores.get)\n",
    "print('Optimal P parameter ' + str(max_key1) + '_' + str(max_value1))\n",
    "\n",
    "all_values2 = Rscores.values()\n",
    "max_value2 = max(all_values2)\n",
    "max_key2 = max(Rscores, key=Rscores.get)\n",
    "print('Optimal R parameter ' + str(max_key2) + '_' + str(max_value2))\n",
    "\n",
    "all_values3 = Fscores.values()\n",
    "max_value3 = max(all_values3)\n",
    "max_key3 = max(Fscores, key=Fscores.get)\n",
    "print('Optimal F parameter ' + str(max_key3) + '_' + str(max_value3))\n",
    "\n",
    "all_values4 = AUCscores.values()\n",
    "max_value4 = max(all_values4)\n",
    "max_key4 = max(AUCscores, key=AUCscores.get)\n",
    "print('Optimal AUC parameter ' + str(max_key4) + '_' + str(max_value4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e83775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
